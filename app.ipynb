{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM9v56yrx2RiRdopVLTQPPL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install docx2txt\n","!pip install tika"],"metadata":{"id":"SOBKZ9M4d1SZ","outputId":"6c43d731-6ec7-4c58-fa31-a058ae739349","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715529146157,"user_tz":-330,"elapsed":26446,"user":{"displayName":"EDA TEAM A","userId":"11727554646797420659"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting docx2txt\n","  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: docx2txt\n","  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=53e275723499e8ca076a5c2dc50ba489ac97e5445439b146d09dd3b7ac7c59a1\n","  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n","Successfully built docx2txt\n","Installing collected packages: docx2txt\n","Successfully installed docx2txt-0.8\n","Collecting tika\n","  Downloading tika-2.6.0.tar.gz (27 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tika) (67.7.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tika) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tika) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tika) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tika) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tika) (2024.2.2)\n","Building wheels for collected packages: tika\n","  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32621 sha256=bac77f96791763db94fd834dce7e28464a654624e62e8fff9ac7dd60c25aaaf7\n","  Stored in directory: /root/.cache/pip/wheels/5f/71/c7/b757709531121b1700cffda5b6b0d4aad095fb507ec84316d0\n","Successfully built tika\n","Installing collected packages: tika\n","Successfully installed tika-2.6.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70VvxRI0GE92","executionInfo":{"status":"ok","timestamp":1715529161446,"user_tz":-330,"elapsed":15302,"user":{"displayName":"EDA TEAM A","userId":"11727554646797420659"}},"outputId":"31d25def-be3c-4efb-bc1d-7ba01a68111d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyngrok\n","  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-7.1.6\n","Collecting Flask_wtf\n","  Downloading flask_wtf-1.2.1-py3-none-any.whl (12 kB)\n","Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from Flask_wtf) (2.2.5)\n","Requirement already satisfied: itsdangerous in /usr/local/lib/python3.10/dist-packages (from Flask_wtf) (2.2.0)\n","Collecting wtforms (from Flask_wtf)\n","  Downloading wtforms-3.1.2-py3-none-any.whl (145 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->Flask_wtf) (3.0.3)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask->Flask_wtf) (3.1.4)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->Flask_wtf) (8.1.7)\n","Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from wtforms->Flask_wtf) (2.1.5)\n","Installing collected packages: wtforms, Flask_wtf\n","Successfully installed Flask_wtf-1.2.1 wtforms-3.1.2\n"]}],"source":["!pip install pyngrok\n","!pip install Flask_wtf"]},{"cell_type":"code","source":["from flask import Flask\n","from pyngrok import ngrok"],"metadata":{"id":"9SnMp30rGRIt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"kyvJXNHMGijJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715529185670,"user_tz":-330,"elapsed":23459,"user":{"displayName":"EDA TEAM A","userId":"11727554646797420659"}},"outputId":"87fca5f2-8516-43bc-8d24-182a4adb70b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install wtforms"],"metadata":{"id":"lNT3bLszedNB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715529191102,"user_tz":-330,"elapsed":5441,"user":{"displayName":"EDA TEAM A","userId":"11727554646797420659"}},"outputId":"18ba3456-1085-4876-cecd-2ac4271beb01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: wtforms in /usr/local/lib/python3.10/dist-packages (3.1.2)\n","Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from wtforms) (2.1.5)\n"]}]},{"cell_type":"code","source":["port_no = 5000"],"metadata":{"id":"mG1TsNyQG3j8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y1j5sN4cLWVL","outputId":"d5a53465-24cc-4e81-a0d7-87f05ee8ecbf","executionInfo":{"status":"ok","timestamp":1715531106322,"user_tz":-330,"elapsed":9442,"user":{"displayName":"EDA TEAM A","userId":"11727554646797420659"}}},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["To acces the Gloable link please click https://6df6-34-125-245-119.ngrok-free.app\n"," * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on http://127.0.0.1:5000\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n","INFO:werkzeug:127.0.0.1 - - [12/May/2024 16:11:14] \"GET / HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [12/May/2024 16:11:14] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n","INFO:werkzeug:127.0.0.1 - - [12/May/2024 16:11:24] \"POST / HTTP/1.1\" 200 -\n"]}],"source":["from flask import Flask, render_template, request\n","from flask_wtf import FlaskForm\n","from wtforms import FileField, SubmitField\n","from wtforms.validators import InputRequired\n","from werkzeug.utils import secure_filename\n","import os\n","import re\n","import nltk\n","import spacy\n","import docx2txt\n","from tika import parser\n","\n","nltk.download(\"punkt\")\n","nltk.download(\"stopwords\")\n","\n","def extract_text_from_pdf(file_path):\n","    try:\n","        parsed_pdf = parser.from_file(file_path)\n","        return parsed_pdf['content']\n","    except Exception as e:\n","        print(f\"Error extracting text from {file_path}: {str(e)}\")\n","        return \"\"\n","\n","#function for extracting text from documents\n","def extract_text_from_doc(file_path):\n","    try:\n","        text = docx2txt.process(file_path)\n","        return text\n","    except Exception as e:\n","        print(f\"Error extracting text from {file_path}: {str(e)}\")\n","        return \"\"\n","\n","def preprocess(txt):\n","    txt = txt.lower() if isinstance(txt, str) else ' '.join(txt).lower() #make lower\n","    txt = re.sub(r'\\n', ' ', txt) # remove /n\n","    txt = re.sub('(http\\S+|www.\\S+)', ' ', txt)  # Remove URLs\n","    txt = re.sub('#\\S+', '', txt) # remove #\n","    txt = re.sub(r'[\\/,.:❖•;]', ' ', txt)  # Remove the specified special characters\n","    txt = re.sub('\\s+', ' ', txt) # replace multiple whitespace characters (such as spaces, tabs, newlines, etc.)\n","    txt = re.sub(r'', '', txt) # remove \n","    txt = nltk.tokenize.word_tokenize(txt) # tokenize the text\n","    txt = [w for w in txt if not w in nltk.corpus.stopwords.words('english')]\n","\n","    return ' '.join(txt)\n","\n","from spacy.matcher import Matcher\n","nlp = spacy.load(\"en_core_web_sm\")\n","# Function to extract name from resume text\n","matcher = Matcher(nlp.vocab)\n","\n","def extract_name(text):\n","    nlp_text = nlp(text)\n","    # Define pattern for first and last name as Proper Nouns\n","    pattern = [[{'POS': 'PROPN'}, {'POS': 'PROPN'}]]\n","    matcher.add('NAME', pattern)\n","    matches = matcher(nlp_text)\n","    for match_id, start, end in matches:\n","        span = nlp_text[start:end]\n","        return span.text\n","\n","# functions to extract mob number\n","def extract_phone_numbers(text):\n","    phone_pattern = r\" (?:\\d[ -]?){9,15} \"\n","    return re.findall(phone_pattern, text)\n","\n","# Function to extract email id\n","def extract_email_addresses(text):\n","    email_pattern = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n","    match = email_pattern.search(text)\n","    return match.group() if match else None\n","\n","#function for extracting skills\n","def extract_skills(text):\n","    skills_keywords = ['skills', 'technical skills', 'personal skills']\n","    end_keywords = ['contact', 'profile', 'interest', 'internship', 'education', 'work history', 'work', 'experience', 'summary', 'achievement', 'achievements', 'certifications', 'projects', 'accomplishments', 'accomplishment', 'work experience', 'qualification']  # Keywords to stop extraction\n","\n","    skill_sections = []\n","    used_keywords = set()  # Store used keywords to avoid duplicates\n","    last_end_index = 0  # Store the last end index to begin searching from there\n","\n","# finds the keywords and extract the content in that\n","    for keyword in skills_keywords:\n","        if keyword not in used_keywords:\n","            start_index = text.find(keyword, last_end_index)\n","            if start_index != -1:\n","                end_index = len(text)\n","                for end_key in end_keywords:\n","                    end_index_candidate = text.find(end_key, start_index + len(keyword))\n","                    if end_index_candidate != -1 and end_index_candidate < end_index:\n","                        end_index = end_index_candidate\n","                extracted_text = text[start_index + len(keyword):end_index].strip()\n","                if extracted_text:\n","                    skill_sections.append(extracted_text)\n","                used_keywords.add(keyword)\n","                last_end_index = end_index\n","\n","    return skill_sections\n","\n","#function for extracting education\n","def extract_education(text):\n","    education_keywords = ['education', 'degree', 'university', 'college', 'qualification']\n","    end_keywords = ['contact', 'profile', 'interest', 'internship', 'languages', 'skills', 'work history', 'experience', 'summary', 'achievement', 'achievements', 'certifications', 'projects', 'accomplishments', 'accomplishment', 'work experience']  # Keywords to stop extraction\n","\n","    education_sections = []\n","    used_keywords = set()\n","    last_end_index = 0\n","\n","# finds the keywords and extract the content in that\n","    for keyword in education_keywords:\n","        if keyword not in used_keywords:\n","            start_index = text.find(keyword, last_end_index)\n","            if start_index != -1:\n","                end_index = len(text)\n","                for end_key in end_keywords:\n","                    end_index_candidate = text.find(end_key, start_index + len(keyword))\n","                    if end_index_candidate != -1 and end_index_candidate < end_index:\n","                        end_index = end_index_candidate\n","                extracted_text = text[start_index + len(keyword):end_index].strip()\n","                if extracted_text:\n","                    education_sections.append(extracted_text)\n","                used_keywords.add(keyword)\n","                last_end_index = end_index\n","\n","    return education_sections\n","\n","#function for extracting work experience\n","def extract_work_experience(text):\n","    experience_keywords = ['internship', 'professional experience', 'experience', 'work experience', 'employment', 'work history']\n","    end_keywords = ['contact', 'profile', 'interest', 'skills', 'languages', 'technical skills', 'education', 'summary', 'achievement', 'certifications', 'projects', 'accomplishments', 'accomplishment', 'qualification']  # Keywords to stop extraction\n","\n","    experience_sections = []\n","    used_keywords = set()\n","    last_end_index = 0\n","\n","#finds the keywords and extract content in that\n","    for keyword in experience_keywords:\n","        if keyword not in used_keywords:\n","            start_index = text.find(keyword, last_end_index)\n","            if start_index != -1:\n","                end_index = len(text)\n","                for end_key in end_keywords:\n","                    end_index_candidate = text.find(end_key, start_index + len(keyword))\n","                    if end_index_candidate != -1 and end_index_candidate < end_index:\n","                        end_index = end_index_candidate\n","\n","                extracted_text = text[start_index + len(keyword):end_index].strip()  # Exclude the keyword itself\n","                if extracted_text:  # Check if the extracted text is not empty\n","                    experience_sections.append(extracted_text)\n","                used_keywords.add(keyword)\n","                last_end_index = end_index\n","\n","    return experience_sections\n","\n","def extract_details(file_path):\n","    text = \"\"\n","    if file_path.endswith('.pdf'):\n","        text = extract_text_from_pdf(file_path)\n","    elif file_path.endswith('.docx'):\n","        text = extract_text_from_doc(file_path)\n","\n","    processed_text = preprocess(text)\n","\n","    # Replace these lines with the function calls you want to use\n","    name = extract_name(processed_text)\n","    phone_numbers = extract_phone_numbers(processed_text)\n","    email_address = extract_email_addresses(text)\n","    skills = extract_skills(processed_text)\n","    education = extract_education(processed_text)\n","    work_experience = extract_work_experience(processed_text)\n","\n","    extracted_data = {\n","        'name': name,\n","        'phone_numbers': phone_numbers,\n","        'email_address': email_address,\n","        'skills': skills,\n","        'education': education,\n","        'work_experience': work_experience\n","    }\n","    return extracted_data\n","\n","def format_extracted_data(extracted_data):\n","\n","    formatted_data = {\n","        'name': extracted_data['name'],\n","        'phone_numbers': ', '.join([number.strip() for number in extracted_data['phone_numbers']]) if extracted_data['phone_numbers'] else None,\n","        'email_address': extracted_data['email_address'],\n","        'skills': ', '.join(extracted_data['skills']) if extracted_data['skills'] else None,\n","        'education': ', '.join(extracted_data['education']) if extracted_data['education'] else None,\n","        'work_experience': ', '.join(extracted_data['work_experience']) if extracted_data['work_experience'] else None\n","    }\n","    return formatted_data\n","\n","# Flask app setup\n","template_folder = \"/content/drive/MyDrive/Resume_Parser/template\"\n","app = Flask(__name__, template_folder=template_folder)\n","ngrok.set_auth_token(\"2gN7hnjcZeiu6vJCaLj8ZTj4oBz_58BGx3VyXXwSXYi54vo7k\")\n","public_url =  ngrok.connect(port_no).public_url\n","app.config['SECRET_KEY'] = 'supersecretkey'\n","app.config['UPLOAD_FOLDER'] = '/content/drive/MyDrive/Resume_Parser/static/file'\n","\n","# Define your FlaskForm for file upload\n","class UploadFileForm(FlaskForm):\n","    file = FileField(\"File\", validators=[InputRequired()])\n","    submit = SubmitField(\"Upload File\")\n","\n","# Route for uploading resumes and processing them\n","@app.route('/', methods=['GET', 'POST'])\n","@app.route('/home', methods=['GET', 'POST'])\n","def home():\n","    form = UploadFileForm()\n","    extracted_data = None\n","\n","    if form.validate_on_submit():\n","        file = form.file.data\n","        if file:\n","            file_path = \"uploads/\" + file.filename\n","            file.save(os.path.join(app.config['UPLOAD_FOLDER'], secure_filename(file.filename)))\n","            extracted_data = extract_details(os.path.join(app.config['UPLOAD_FOLDER'], secure_filename(file.filename)))\n","            extracted_data = format_extracted_data(extracted_data)  # Format extracted data here\n","\n","            return render_template('index.html', form=form, extracted_data=extracted_data)\n","\n","    return render_template('index.html', form=form, extracted_data=extracted_data)\n","\n","print(f\"To acces the Gloable link please click {public_url}\")\n","\n","app.run(port=port_no)\n"]}]}